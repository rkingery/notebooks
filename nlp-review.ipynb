{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f737dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchtext\n",
    "\n",
    "import timm\n",
    "import fastai.vision.all as fastai\n",
    "from fastai.callback.schedule import Learner\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboardX import SummaryWriter\n",
    "%load_ext tensorboard\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ac4471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d49df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, optimizer='sgd', lr=0.001, weight_decay=0, momentum=0, betas=(0.9, 0.999), eps=1e-8):\n",
    "    if optimizer == 'sgd':\n",
    "        opt = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=lr, \n",
    "            weight_decay=weight_decay, \n",
    "            momentum=momentum\n",
    "        )\n",
    "    if optimizer == 'adam':\n",
    "        opt = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            betas=betas,\n",
    "            eps=eps\n",
    "        )\n",
    "    return opt\n",
    "\n",
    "def train_model(train_data, model, opt, loss_fn, test_data=None, num_epochs=10, plot_loss=True, batch_size=32,\n",
    "               tensorboard=False, print_loss=True, show_batches_bar=False, shuffle=True):\n",
    "    if tensorboard:\n",
    "        writer = SummaryWriter()\n",
    "    losses = []\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n",
    "    if test_data is not None:\n",
    "        test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model = model.train()\n",
    "        batch_losses = []\n",
    "        batch_correct = []\n",
    "        iterator = tqdm(train_loader, leave=False) if show_batches_bar else train_loader\n",
    "        for X, y in iterator:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            opt.zero_grad()\n",
    "            yhat = model(X)\n",
    "            loss = loss_fn(yhat, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            batch_losses.append(float(loss)* batch_size)\n",
    "            batch_correct.append(float((yhat.argmax(dim=1) == y).sum().cpu()))\n",
    "        train_loss = sum(batch_losses) / len(train_data)\n",
    "        train_acc = sum(batch_correct) / len(train_data)\n",
    "        losses.append(train_loss)\n",
    "        \n",
    "        if test_data is not None:\n",
    "            model = model.eval()\n",
    "            batch_losses = []\n",
    "            batch_correct = []\n",
    "            iterator = tqdm(test_loader, leave=False) if show_batches_bar else test_loader\n",
    "            for X, y in iterator:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                opt.zero_grad()\n",
    "                yhat = model(X)\n",
    "                loss = loss_fn(yhat, y)\n",
    "                batch_losses.append(float(loss) * batch_size)\n",
    "                batch_correct.append(float((yhat.argmax(dim=1) == y).sum().cpu()))\n",
    "            test_loss = sum(batch_losses) / len(test_data)\n",
    "            test_acc = sum(batch_correct) / len(test_data)\n",
    "        else:\n",
    "            test_loss = -999\n",
    "            test_acc = -999\n",
    "\n",
    "        if tensorboard:\n",
    "            writer.add_scalar(\"Training Loss\", train_loss, epoch+1)\n",
    "            writer.add_scalar(\"Training Accuracy\", train_acc, epoch+1)\n",
    "            writer.add_scalar(\"Test Loss\", test_loss, epoch+1)\n",
    "            writer.add_scalar(\"Test Accuracy\", test_acc, epoch+1)\n",
    "        if print_loss:\n",
    "            s1 = f'epoch: {epoch+1: <3}   ' \n",
    "            s2 = f'train loss: {round(train_loss, 4): <6}   train acc: {round(train_acc, 4): <6}   ' \n",
    "            s3 = f'test loss: {round(test_loss, 4): <6}   test acc: {round(test_acc, 4): <6}'\n",
    "            print(s1 + s2 + s3)\n",
    "    if plot_loss:\n",
    "        plt.plot(range(len(losses)), losses)\n",
    "    if tensorboard:\n",
    "        writer.flush()\n",
    "        writer.close()\n",
    "    return model\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02227860",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "\n",
    "- Neural network used to learn input/output relationships for examples that have some kind of sequential, temporal relationship. Allows the network to use learned shared features to take into account the context (sequence order) of a given example.\n",
    "- Maps a temporal sequence $x_1,\\cdots,x_T$ to another temporal sequence $y_1,\\cdots,y_{T'}$ by learning a function of past and present input values: $y_t = f_t(x_1,\\cdots,x_t)$.\n",
    "- Each $x = (x_1,\\cdots,x_T) \\rightarrow y = (y_1,\\cdots,y_{T'})$ pair becomes a \"training example\" in a sense. The output of an RNN layer for a particular sequence element $t=1,\\cdots,T$ is given by\n",
    "$$ h_t = \\tanh(W_{xh} x_t + b_{xh} + W_{hh} h_{t-1} + b_{hh}),$$\n",
    "$$ \\hat y_t = \\sigma(W_{hy} h_t + b_{hy}).$$\n",
    "- One needs to initialize $h_0$ to have some value. One can use zeros, a random initialization, or (for a stateful RNN) use the output $h_0 \\equiv h_T^{prev}$ from the previous batch.\n",
    "- Typically the tanh function is used for hidden activation function in RNNs instead of the ReLU.\n",
    "- Input and output sequences need not have the same length, nor need one or the other be a sequence at all.\n",
    "- Each unit of the RNN has an input state, hidden state, and output state. All params are shared across all elements in the sequence, so only $x_t, h_t$ contain information about position.\n",
    "- Typically $T, T'$ are not actually the length of the input/output sequences, but a defined sequence length. This means each sequence gets split into $k$ chunks of length $T$, potentially breaking the ordering between those chunks.\n",
    "- For sequences of size less than $T,T'$, padding the input/output with `<PAD>` tokens can be used to fill in the gaps.\n",
    "- The standard RNN is only unidirectional. Sequences read left to right. To take advantage of \"acausal\" sequence information, one can use a bidirectional RNN (BiRNN) that uses both left-to-right and right-to-left hidden units.\n",
    "- The loss in an RNN is the sum of the output losses: \n",
    "$$L(y,\\hat y) = L_1(y_1,\\hat y_1) + \\cdots + L_{T'}(y_{T'},\\hat y_{T'}).$$\n",
    "- Backpropagation on an RNN layer is done \"through time\" (BPTT). BPTT works by starting at $y_{T'}$ and backpropagating backwards through time all the way to $x_1$. Since the $W_t$ gradient $\\frac{\\partial L}{\\partial W_t} \\propto W_{t+1} \\dots W_T$, RNNs with long sequence lengths are vulnerable to gradient vanishing. This makes it hard for items in long sequences that are far apart from each other to influence each other.\n",
    "- For sequence classification tasks, e.g. sentiment classification, one has $T'=1$. To use the full context of the sequence, one typically puts the \"useful\" classification vector last in the $x_T$ line. Such RNNs are \"many-to-one\". When $T,T'>1$ the RNN is typically called \"many-to-many\" or \"seq2seq\". When $T=1$ but $T'>1$ the RNN is called \"one-to-many\"; these show up for example in sequence generation tasks.\n",
    "- Encoder-decoder architectures are also possible for many-to-many RNNs. These are used in applications like machine translation. In this scenario, the inputs are fed into an encoder half that outputs nothing. The encoder feeds its hidden units into a decoder that inputs nothing, but outputs the output sequence. Typically in these, the output $\\hat y_{t-1}$ is fed as an effective input into $x_t \\equiv \\hat y_{t-1}$.\n",
    "- In PyTorch, sequences are typically fed into RNNs with the order: `(sequence_length, batch_size, num_features)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94310636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLayer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, \n",
    "                 hidden_activation=torch.tanh, output_activation=lambda x: x):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.output_activation = output_activation\n",
    "        self.linear_in = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.linear_hidden = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.linear_out = nn.Linear(self.hidden_size, self.output_size)\n",
    "    \n",
    "    def forward(self, x, h=None):\n",
    "        seq_len, batch_size = x.shape[0], x.shape[1]\n",
    "        hidden_shape = (1, batch_size, self.hidden_size)\n",
    "        output_shape = (seq_len, batch_size, self.output_size)\n",
    "        h = torch.zeros(hidden_shape) if h is None else h\n",
    "        yhat = torch.zeros(output_shape)\n",
    "        for t in range(seq_len):\n",
    "            h = self.hidden_activation(self.linear_in(x[t]) + self.linear_hidden(h))\n",
    "            yhat[t] = self.output_activation(self.linear_out(h))\n",
    "        return yhat, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d89f7855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 10]), torch.Size([1, 3, 15]), torch.Size([5, 3, 20]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = RNNLayer(10, 15, 20, torch.tanh, torch.sigmoid) # input_size, hidden_size, output_size\n",
    "x = torch.randn(5, 3, 10) # seq_len, batch_size, input_size\n",
    "h0 = torch.zeros(1, 3, 15) # num_layers, batch_size, hidden_size\n",
    "yhat, h = rnn(x, h0)\n",
    "x.shape, h.shape, yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da70ad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 10]), torch.Size([1, 3, 20]), torch.Size([5, 3, 20]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNN(10, 20, 1) # input_size, hidden_size, num_layers\n",
    "x = torch.randn(5, 3, 10) # seq_len, batch_size, input_size\n",
    "h0 = torch.zeros(1, 3, 20) # num_layers, batch_size, hidden_size\n",
    "yhat, h = rnn(x, h0)\n",
    "x.shape, h.shape, yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52389d",
   "metadata": {},
   "source": [
    "## Modified RNNs\n",
    "\n",
    "The simple RNN is highly susceptible to gradient vanishing/explosion, making it difficult to learn long range dependencies in sequences. To get around this and enable longer sequences, typically one modifies RNNs slightly by adding \"gates\" to each computation cell, which in reality are just more parameters in the $x_t \\rightarrow y_t$ mappings.\n",
    "\n",
    "**GRUs:** Uses a \"relevance\" gate $r_t$ and an \"update\" gate $u_t$. Informally, the relevance gate decides whether the hidden cell should be updated in response to the previous cell, and the update gate weights how much the new cell is important relative to previous cells via a weighted average.\n",
    "$$\\color{red}{u_t = \\sigma(W_{uu}u_{t-1} + b_{uu} + W_{xu}x_t + b_{xu})}$$\n",
    "$$\\color{red}{r_t = \\sigma(W_{rr}r_{t-1} + b_{rr} + W_{xr}x_t + b_{xr})}$$\n",
    "$$\\tilde h_t = \\tanh(W_{hh}(\\color{red}{r_t \\ast} h_{t-1}) + b_{hh} + W_{xh}x_t + b_{xh})$$\n",
    "$$h_t = \\color{red}{u_t \\ast} \\tilde h_t \\color{red}{+ (1-u_t) \\ast h_{t-1}}$$\n",
    "$$\\hat y_t = \\sigma(W_{hy} h_t + b_{hy}).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ab8a125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 10]), torch.Size([1, 3, 20]), torch.Size([5, 3, 20]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.GRU(10, 20, 1) # input_size, hidden_size, num_layers\n",
    "x = torch.randn(5, 3, 10) # seq_len, batch_size, input_size\n",
    "h0 = torch.zeros(1, 3, 20) # num_layers, batch_size, hidden_size\n",
    "yhat, h = rnn(x, h0)\n",
    "x.shape, h.shape, yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cce73b",
   "metadata": {},
   "source": [
    "**LSTMs:** Uses 3 gates, an \"update\" gate $i_t$, a \"forget\" gate $f_t$, and an \"output\" gate $o_t$. Informally, the update gate decides how important the new hidden cell is, the forget gate decides how much of the previous cell to forget, and the output cell decides how relevant the hidden cell is to the output $h_t$.\n",
    "$$\\color{red}{i_t = \\sigma(W_{ii}i_{t-1} + b_{ii} + W_{xi}x_t + b_{xi})}$$\n",
    "$$\\color{red}{f_t = \\sigma(W_{ff}f_{t-1} + b_{ff} + W_{xf}x_t + b_{xf})}$$\n",
    "$$\\color{red}{o_t = \\sigma(W_{oo}o_{t-1} + b_{oo} + W_{xo}x_t + b_{xo})}$$\n",
    "$$\\tilde c_t = \\tanh(W_{cc} \\color{red}{h_{t-1}} + b_{cc} + W_{xc}x_t + b_{xc})$$\n",
    "$$c_t = \\color{red}{i_t \\ast} \\tilde c_t + \\color{red}{f_t \\ast c_{t-1}}$$\n",
    "$$h_t = \\color{red}{o_t \\ast \\tanh(}c_t\\color{red}{)}$$\n",
    "$$ \\hat y_t = \\sigma(W_{hy} \\color{red}{h_t} + b_{hy}).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5c6c4feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 10]),\n",
       " torch.Size([1, 3, 20]),\n",
       " torch.Size([1, 3, 20]),\n",
       " torch.Size([5, 3, 20]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 1) # input_size, hidden_size, num_layers\n",
    "x = torch.randn(5, 3, 10) # seq_len, batch_size, input_size\n",
    "c0 = torch.zeros(1, 3, 20) # num_layers, batch_size, hidden_size\n",
    "h0 = torch.zeros(1, 3, 20) # num_layers, batch_size, hidden_size\n",
    "yhat, (h, c) = rnn(x, (h0, c0))\n",
    "x.shape, h.shape, c.shape, yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e8ba0",
   "metadata": {},
   "source": [
    "**Bidirectional RNNs (BiRNNs):** Regular RNNs are \"causal\", meaning $\\hat y_t$ is only a function or *past inputs* $x_1,\\cdots,x_{t-1}$. To allow RNNs to be \"acausal\", one can use BiRNNs, which use hidden activations in both the past and future directions, $h_t$ and $j_t$. One then combines them at the end to get the output predictions.\n",
    "\n",
    "$$\n",
    "h_t = \\tanh(W_{xh} x_t + b_{xh} + W_{hh} h_{t-1} + b_{hh}) \\\\\n",
    "\\color{red}{j_t = \\tanh(W_{xj} x_t + b_{xj} + W_{jj} j_{t+1} + b_{jj})} \\\\\n",
    "\\hat y_t = \\sigma(W_{hy} h_t + b_{hy} \\color{red}{+ W_{j y} j_t + b_{j y}}).\n",
    "$$\n",
    "\n",
    "The downside of a BiRNN is that predictions can't be made in real time. One must wait on the whole sequence to get a prediction even for $t=1$. They are commonly used in NLP, where knowing \"both sides\" of a sentence can make sense when predicting from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "56256b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 10]),\n",
       " torch.Size([2, 3, 20]),\n",
       " torch.Size([1, 3, 20]),\n",
       " torch.Size([1, 3, 20]),\n",
       " torch.Size([5, 3, 40]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNN(10, 20, 1, bidirectional=True) # input_size, hidden_size, num_layers\n",
    "x = torch.randn(5, 3, 10) # seq_len, batch_size, input_size\n",
    "hj0 = torch.zeros(2, 3, 20) # 2 * num_layers, batch_size, hidden_size\n",
    "yhat, hj = rnn(x, hj0)\n",
    "h, j = hj[0][None, :], hj[1][None, :]\n",
    "x.shape, hj.shape, h.shape, j.shape, yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251f654",
   "metadata": {},
   "source": [
    "**Deep RNNs (DRNNs):** RNNs can be stacked in succession to form layers, as with MLPs. The output of one layer gets fed into the next layer, in succession. Deep RNNs can be useful for more complex sequence prediction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "45178644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 10]), torch.Size([2, 3, 20]), torch.Size([5, 3, 40]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.RNN(10, 20, 3) # input_size, hidden_size, num_layers\n",
    "x = torch.randn(5, 3, 10) # seq_len, batch_size, input_size\n",
    "h0 = torch.zeros(2, 3, 20) # num_layers, batch_size, hidden_size\n",
    "yhat, h = rnn(x, h0)\n",
    "x.shape, h.shape, yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5925d2",
   "metadata": {},
   "source": [
    "# Text Processing Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9495a220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,\n",
       " 6,\n",
       " [215, 170, 199, 124, 214, 292],\n",
       " ['As the Nameless officially do not exist , the upper echelons of the Gallian Army exploit the concept of plausible \\n deniability in order to send them on missions that would otherwise make Gallia lose face in the war',\n",
       "  'While at times \\n this works to their advantage , such as a successful incursion into Imperial territory , other orders cause certain \\n members of the 422nd great distress',\n",
       "  'One such member , John , becomes so enraged that he abandons his post and \\n defects into the ranks of Calamity Raven , attached to the ideal of Darcsen independence proposed by their leader , \\n Dahau',\n",
       "  'At the same time , elements within Gallian Army Command move to erase the Nameless in order to protect their \\n own interests',\n",
       "  'Feared by both allies and enemies , and combined with the presence of a traitor within their ranks , \\n the 422nd desperately move to keep themselves alive while at the same time fight to help the Gallian war effort',\n",
       "  \"This continues until the Nameless 's commanding officer , Ramsey Crowe , who had been kept under house arrest , is \\n escorted to the capital city of Bath in order to present evidence hated the weary soldiers and expose the real \\n traitor , the Gallian General that had accused Kurt of Treason\"])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig = \"\"\"\n",
    " As the Nameless officially do not exist , the upper echelons of the Gallian Army exploit the concept of plausible \n",
    " deniability in order to send them on missions that would otherwise make Gallia lose face in the war . While at times \n",
    " this works to their advantage , such as a successful incursion into Imperial territory , other orders cause certain \n",
    " members of the 422nd great distress . One such member , John , becomes so enraged that he abandons his post and \n",
    " defects into the ranks of Calamity Raven , attached to the ideal of Darcsen independence proposed by their leader , \n",
    " Dahau . At the same time , elements within Gallian Army Command move to erase the Nameless in order to protect their \n",
    " own interests . Feared by both allies and enemies , and combined with the presence of a traitor within their ranks , \n",
    " the 422nd desperately move to keep themselves alive while at the same time fight to help the Gallian war effort . \n",
    " This continues until the Nameless 's commanding officer , Ramsey Crowe , who had been kept under house arrest , is \n",
    " escorted to the capital city of Bath in order to present evidence hated the weary soldiers and expose the real \n",
    " traitor , the Gallian General that had accused Kurt of Treason .\n",
    "\"\"\"\n",
    "\n",
    "corpus = [doc.strip() for doc in orig.split('.') if len(doc.strip()) > 0]\n",
    "labels = [len(doc) for doc in corpus]\n",
    "\n",
    "len(corpus), len(labels), labels, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fd8cd97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_special_tokens(text):\n",
    "    # put xxup token before words in all caps (easy way to recognize info from capitalizing a word)\n",
    "    text = re.sub(r'(\\b[A-Z][A-Z0-9]*\\b)', r' xxup \\1 ', text)\n",
    "    # put xxcap token before words with capitalized first letter (easy way to recognize first word in a sentence)\n",
    "    text = re.sub(r'(\\b[A-Z][a-z0-9]+\\b)', r' xxcap \\1 ', text)\n",
    "    # insert beginning and end of sentence tokens xxbos, xxeos after a period, at beginning, and strip extra xxbos\n",
    "    # text = re.sub(r'( [.]+ )', r' xxeos \\1 xxbos ', text)\n",
    "    # text = ' xxbos ' + text\n",
    "    # text = text[:-7]\n",
    "    # insert beginning and end of document tokens xxbod, xxeod\n",
    "    text = ' xxbed ' + text + ' xxeod '\n",
    "    return text\n",
    "\n",
    "def normalize_text(text, remove_stopwords=False, stem_text=False, replace_punct=False):\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    from nltk.corpus import stopwords\n",
    "    import re, string\n",
    "\n",
    "    # converts common patterns into special tokens\n",
    "    text = sub_special_tokens(text)\n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # put spaces between punctuation (eg: 9.Blah -> 9 . Blah)\n",
    "    puncts = r'[' + re.escape(string.punctuation) + r']'\n",
    "    text = re.sub('(?<! )(?=' + puncts + ')|(?<=' + puncts + ')(?! )', r' ', text)\n",
    "    if replace_punct:\n",
    "        # replace all punctuation with xxpunct\n",
    "        text = re.sub(r\"[^\\w\\s]\",' xxpunct ',text)\n",
    "    # convert all other numbers to xxnum token (e.g. 123, 1.2.3, 1-2-3 -> xxnum)\n",
    "    text = re.sub(r'\\b([.-]*[0-9]+[.-]*)+\\b', ' xxnum ', text)\n",
    "    # remove nltk's common set of stop words (common for classical NLP analysis)\n",
    "    if remove_stopwords:\n",
    "        stop_words = stopwords.words('english')\n",
    "        text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    # stem words using nltk snowball stemmer, e.g. converts {run, running, runs} all to \"run\"\n",
    "    if stem_text:\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_text = ''\n",
    "        for word in text.split():\n",
    "                stemmed_text = stemmed_text + stemmer.stem(word) + ' '\n",
    "        text = stemmed_text\n",
    "    # strip new lines\n",
    "    text = re.sub(r'\\n',' ',text)\n",
    "    # sub the occurance of 2 or more spaces with a single space\n",
    "    text = re.sub(r'[ ]{2,}',' ',text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "b768d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each document in corpus (list of doc strings)\n",
    "# given combined corpus \"word_1 word_2 ...\"\n",
    "# normalize document: \"norm_word_1 norm_word_2 ...\"\n",
    "    # insert relevant special tokens: begin/end of sentence, begin/end of document, caps, all caps, etc\n",
    "# tokenize: get list of tokens [tok_1, tok_2, ...]\n",
    "def tokenize_corpus(corpus, normalizer, tokenizer, *args, **kwargs):\n",
    "    normalized_corpus = [normalizer(doc) for doc in corpus]\n",
    "    tokens = [tokenizer(doc).text.split(' ') for doc in normalized_corpus]\n",
    "    return tokens\n",
    "\n",
    "# vocab: get a dict converting each token to ints\n",
    "# numericalize: use vocab to convert list of tokens to list of ints [int_tok_1, int_tok_2, ...]\n",
    "def numericalize_tokens(tokens, vocab=None, pad_last=True):\n",
    "    if vocab is None:\n",
    "        vocab = list(set([tok for doc in tokens for tok in doc]))\n",
    "        if pad_last:\n",
    "            vocab = vocab + ['xxpad']\n",
    "    vocab_size = len(vocab)\n",
    "    stoi = {vocab[i]: i for i in range(vocab_size)}\n",
    "    itos = {i: vocab[i] for i in range(vocab_size)}\n",
    "    nums = [[stoi[token] for token in doc] for doc in tokens]\n",
    "    return nums, stoi, itos, vocab\n",
    "\n",
    "# batchify numerical tokens into n_batches batches of shape (seq_len, batch_size)\n",
    "    # pad batch items with less than batch_size tokens so all have same length\n",
    "    # items in seqs should preserve token ordering, so tok_1 < tok_2 < ...\n",
    "    # items in batches should preserve sequence ordering, so item_1 < item_2 < ...\n",
    "# return batchified tokens in tuple of tensors of shape (seq_len, batch_size)\n",
    "def sequify(data, seq_len, pad_num, labels=None, flatten=False):\n",
    "    def pad_seqs(seqs_list, pad_num):\n",
    "        for seqs in seqs_list:\n",
    "            leftover_len = len(seqs[-1])\n",
    "            seqs[-1] = seqs[-1] + [pad_num for _ in range(seq_len - leftover_len)]\n",
    "        return seqs_list\n",
    "    def flatten_seq(sequence):\n",
    "            return [seq for doc in sequence for seq in doc]\n",
    "    \n",
    "    seqs = [[x[i:i+seq_len] for i in range(0, len(x), seq_len)] for x in data]\n",
    "    seq_data = pad_seqs(seqs, pad_num)\n",
    "    if labels is not None:\n",
    "        seq_labels = [[labels[i] for seq in seq_data[i]] for i in range(len(seq_data))]\n",
    "        seq_data = flatten_seq(seq_data) if flatten else seq_data\n",
    "        seq_labels = flatten_seq(seq_labels) if flatten else seq_labels\n",
    "        return seq_data, seq_labels\n",
    "    else:\n",
    "        seq_data = flatten_seq(seq_data) if flatten else seq_data\n",
    "        return seq_data    \n",
    "\n",
    "def batchify(seqs, batch_size, labels=None, pad_num=-1):\n",
    "    batchified = [[seq[i: i+batch_size] for i in range(0, len(seq), batch_size)] for seq in seqs]\n",
    "    batched_data = [tuple(torch.tensor(batch).T.long() for batch in batchified[i]) for i in range(len(batchified))]\n",
    "    if labels is not None:\n",
    "        batched_labels = [[[labels[i] for y in x] for x in batchified[i]] for i in range(len(batchified))]\n",
    "        return batched_data, batched_labels\n",
    "    else:\n",
    "        return batched_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "772cc5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize_corpus(corpus, normalize_text, nlp)\n",
    "nums, stoi, itos, vocab = numericalize_tokens(tokens, pad_last=True)\n",
    "seq_data, seq_labels = sequify(nums, seq_len=10, pad_num=len(vocab)-1, labels=labels)\n",
    "batched_data, batched_labels = batchify(seq_data, batch_size=3, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "a995ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "emb_size = 100\n",
    "\n",
    "class SelectItem(nn.Module):\n",
    "    def __init__(self, idx):\n",
    "        super().__init__()\n",
    "        self.idx = idx\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[0][self.idx]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Embedding(vocab_size, emb_size),\n",
    "    nn.LSTM(emb_size, 100, 1),\n",
    "    SelectItem(idx=-1),  # selects the last LSTM output y_T to feed into the linear layer\n",
    "    nn.Linear(100, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "cd50dce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[115,  30],\n",
       "         [114,  87],\n",
       "         [  7,  31],\n",
       "         [132,  23],\n",
       "         [ 54,  21],\n",
       "         [134, 136],\n",
       "         [ 50, 136],\n",
       "         [  0, 136],\n",
       "         [129, 136],\n",
       "         [ 18, 136]]),\n",
       " [215, 215, 215],\n",
       " tensor([[-0.0860],\n",
       "         [ 0.0422]]))"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = batched_data[0][-1], batched_labels[0][0]\n",
    "yhat = model(X).detach()\n",
    "X, y, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "3de1647f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'them on missions that would otherwise make xxcap gallia lose face in the war xxeod xxpad xxpad xxpad xxpad xxpad'"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def batch_to_text(batch, itos, batch_first=True):\n",
    "    if isinstance(batch, torch.Tensor):\n",
    "        batch = batch.numpy()\n",
    "    elif isinstance(batch, list):\n",
    "        batch = np.array(batch)\n",
    "    if not batch_first:\n",
    "        batch = batch.T\n",
    "    if len(batch.shape) == 1:\n",
    "        batch = batch[None, :]\n",
    "    return ' '.join(itos[word] for seq in batch for word in seq)\n",
    "\n",
    "batch_to_text(X, itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "1b0e6940",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sequify(nums, pad_num=len(vocab)-1, seq_len=10, labels=labels, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "dae88e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Dataset(torch.tensor(X).long(), torch.tensor(y).float())\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "5039371a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  5,   0, 131,  31,   0,  92,  72,  80,  62,  12],\n",
       "         [ 90,  31,  82, 105,  96,  31,   0,  35,   0,  83],\n",
       "         [127,  31,  11,  96,  64, 126,  87,  46,  16,  70],\n",
       "         [115, 114,   7, 132,  54, 134,  50,   0, 129,  18],\n",
       "         [ 30,  87,  31,  23,  21, 136, 136, 136, 136, 136],\n",
       "         [  5,   0,   1,  71,  63,  86,  45,  16,  97, 119],\n",
       "         [ 90,  32, 131,  55,  84, 130,  25,   0, 112, 116],\n",
       "         [ 90, 111,  14,  52,  95,  67,  96,  31,  34,  57]]),\n",
       " tensor([215, 215, 215, 215, 215, 170, 170, 170]))"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(data, batch_size=8, shuffle=False)\n",
    "xi, yi = next(iter(data_loader))\n",
    "xi, yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "31f53195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbed xxcap as the xxcap nameless officially do not exist , the upper echelons of the xxcap gallian xxcap army exploit the concept of plausible deniability in order to send'"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_to_text(batched_data[0][0], itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "0b535558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0835],\n",
       "        [-0.0509],\n",
       "        [-0.0532],\n",
       "        [-0.0860],\n",
       "        [ 0.0422],\n",
       "        [-0.1095],\n",
       "        [-0.0509],\n",
       "        [ 0.0303]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xi.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec927e",
   "metadata": {},
   "source": [
    "# Language Modeling\n",
    "\n",
    "- Uses a sequence of tokens to predict the most likely next tokens, e.g. `I am drinking orange` -> `juice .`\n",
    "- Given a sequence of numericalized tokens:\n",
    "    - Pad the seqs so they all have the same length (often the length of the max seq)\n",
    "    - Set the input $x$ to be the list of sequences (one-hot encoded if no embedding layer)\n",
    "    - Set the output $y$ to be the list of sequences shifted to the right by one (one-hot encoded if no embedding layer)\n",
    "    - The goal is to learn to predict each $y_t|x_t$ where $x_t \\equiv y_{t-1}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86bf7da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aachenosaurus',\n",
       " 'Aardonyx',\n",
       " 'Abdallahsaurus',\n",
       " 'Abelisaurus',\n",
       " 'Abrictosaurus',\n",
       " 'Abrosaurus',\n",
       " 'Abydosaurus',\n",
       " 'Acanthopholis',\n",
       " 'Achelousaurus',\n",
       " 'Acheroraptor']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('/Users/rkingery/repos/coursera-deep-learning-specialization/C5 - Sequence Models/Week 1/Dinosaur Island -- Character-level language model')\n",
    "df = pd.read_csv(path/'dinos.txt', sep=\" \", header=None)\n",
    "corpus = df.values.flatten().tolist()\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d32583c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'a', 'u', 'r', 'u', 's']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [list(doc.lower()) for doc in corpus]\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4be457f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l', 'e', 'q', 'w', 'p', 's', 'v', 'x', 'c', 'r', 'f', 'z', 'y', 'b', 'k', 'g', 't', 'm', 'j', 'i', 'n', 'o', 'u', 'd', 'h', 'a', '\\n', '<PAD>']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(set(''.join(char for doc in tokens for char in doc)))\n",
    "vocab += ['\\n', '<PAD>']\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b58de2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "stoi = {vocab[i]: i for i in range(vocab_size)}\n",
    "itos = {i: vocab[i] for i in range(vocab_size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43932787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(doc) for doc in tokens])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d91c08eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 25, 8, 24, 1, 20, 21, 5, 25, 22, 9, 22, 5]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [[stoi[char] for char in doc] for doc in tokens]\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9017118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 25, 8, 24, 1, 20, 21, 5, 25, 22, 9, 22, 5, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27]\n"
     ]
    }
   ],
   "source": [
    "def pad(seq, pad_token, max_len):\n",
    "    return seq + [pad_token for _ in range(max_len - len(seq))]\n",
    "    \n",
    "seqs_padded = [pad(seq, stoi['<PAD>'], max_len) for seq in sequences]\n",
    "print(seqs_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff1bb996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 8, 24, 1, 20, 21, 5, 25, 22, 9, 22, 5, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27]\n"
     ]
    }
   ],
   "source": [
    "seqs_shifted = [seq[1:] + [stoi['<PAD>']] for seq in seqs_padded]\n",
    "print(seqs_shifted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "778b82e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a a c h e n o s a u r u s <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>',\n",
       " 'a c h e n o s a u r u s <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_to_text(seqs_padded[0], itos), batch_to_text(seqs_shifted[0], itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f524062e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 26, 28])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_seqs = F.one_hot(torch.tensor(seqs_padded)).float()\n",
    "one_hot_seqs.shape # n_examples, seq_len , vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf023d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 26, 28])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_shifted = F.one_hot(torch.tensor(seqs_shifted)).float()\n",
    "one_hot_shifted.shape # n_examples, seq_len , vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0e1d7e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (rnn): RNN(28, 50, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=100, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "seq_len = max_len\n",
    "\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, output_size, n_layers=1, bidirectional=False, rnn=nn.RNN):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = rnn(vocab_size, hidden_size, n_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        factor = 2 if bidirectional else 1\n",
    "        self.fc = nn.Linear(factor * hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        a, h = self.rnn(x)\n",
    "        yhat = self.fc(a)\n",
    "        return yhat\n",
    "    \n",
    "model = LanguageModel(vocab_size, 50, vocab_size, n_layers=1, bidirectional=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "054e9880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 26, 28]), torch.Size([1, 26, 28]))"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = one_hot_seqs[0][None, :] # 1, seq_len, vocab_size\n",
    "yhat = model(x)\n",
    "x.shape, yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "9ab1420a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1536, 26, 28]), torch.Size([1536, 26, 28]))"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = one_hot_seqs\n",
    "Y = one_hot_shifted\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "112e7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_language_model(train_data, model, opt, loss_fn, test_data=None, num_epochs=1000, plot_loss=True, \n",
    "                         batch_size=32, print_stats=True, show_batches_bar=False, shuffle=True, max_to_clip=5.,\n",
    "                         print_every=1):\n",
    "    train_size = train_data[0][0].shape[0]\n",
    "    epoch_losses = []\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle)\n",
    "    if test_data is not None:\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model = model.train()\n",
    "        batch_losses = []\n",
    "        iterator = tqdm(train_loader, leave=False) if show_batches_bar else train_loader\n",
    "        for x, y in iterator:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            opt.zero_grad()\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_to_clip)\n",
    "            opt.step()\n",
    "            batch_losses.append(float(loss) * batch_size)\n",
    "        train_loss = sum(batch_losses) / train_size\n",
    "        epoch_losses.append(train_loss)\n",
    "        \n",
    "        if test_data is not None:\n",
    "            test_size = test_data[0][0].shape[0]\n",
    "            model = model.eval()\n",
    "            batch_losses = []\n",
    "            iterator = tqdm(test_loader, leave=False) if show_batches_bar else test_loader\n",
    "            for x, y in iterator:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                opt.zero_grad()\n",
    "                yhat = model(x)\n",
    "                loss = loss_fn(yhat, y)\n",
    "                batch_losses.append(float(loss) * batch_size)\n",
    "            test_loss = sum(batch_losses) / test_size\n",
    "        else:\n",
    "            test_loss = -999\n",
    "\n",
    "        if print_stats and epoch % print_every == 0:\n",
    "            s1 = f'epoch: {epoch: <3}   ' \n",
    "            s2 = f'train loss: {round(train_loss, 4): <6}   test loss: {round(test_loss, 4): <6}' \n",
    "            print(s1 + s2)\n",
    "    if plot_loss:\n",
    "        plt.plot(range(len(epoch_losses)), epoch_losses)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "1b868ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113bd6e4e8e140b4baa929979d892a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0     train loss: 165.4859   test loss: 152.0459\n",
      "epoch: 50    train loss: 105.9618   test loss: 105.6813\n",
      "epoch: 100   train loss: 103.5779   test loss: 103.284\n",
      "epoch: 150   train loss: 102.6798   test loss: 102.4643\n",
      "epoch: 200   train loss: 102.0696   test loss: 101.8733\n",
      "epoch: 250   train loss: 101.8943   test loss: 101.697\n",
      "epoch: 300   train loss: 101.5912   test loss: 101.4494\n",
      "epoch: 350   train loss: 101.5171   test loss: 101.4886\n",
      "epoch: 400   train loss: 101.4544   test loss: 101.2585\n",
      "epoch: 450   train loss: 101.4821   test loss: 101.3464\n",
      "epoch: 500   train loss: 101.4313   test loss: 101.3246\n",
      "epoch: 550   train loss: 101.3257   test loss: 101.1806\n",
      "epoch: 600   train loss: 101.205   test loss: 100.9912\n",
      "epoch: 650   train loss: 101.078   test loss: 100.9934\n",
      "epoch: 700   train loss: 101.1608   test loss: 101.0752\n",
      "epoch: 750   train loss: 101.0649   test loss: 100.9337\n",
      "epoch: 800   train loss: 101.1896   test loss: 101.0151\n",
      "epoch: 850   train loss: 101.2149   test loss: 101.0049\n",
      "epoch: 900   train loss: 100.954   test loss: 100.9027\n",
      "epoch: 950   train loss: 100.9804   test loss: 100.7855\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = Dataset(X, Y)\n",
    "model = LanguageModel(vocab_size, 50, vocab_size, n_layers=1, rnn=nn.GRU, bidirectional=False).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = get_optimizer(model, optimizer='adam', lr=0.01, weight_decay=0.0001)\n",
    "model = train_language_model(data, model, opt, loss_fn, num_epochs=1000, batch_size=128, max_to_clip=5., \n",
    "                             test_data=data, print_every=1000//20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c6d325e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p a c h y s p o n d y l u s                        \n",
      "h l h e e o o l o l l u r                          \n"
     ]
    }
   ],
   "source": [
    "idx = 1000\n",
    "x = X[idx]\n",
    "y = Y[idx]\n",
    "yhat = model(x)\n",
    "print(batch_to_text(x.argmax(dim=-1), itos).replace('<PAD>', ' '))\n",
    "print(batch_to_text(yhat.argmax(dim=-1), itos).replace('<PAD>', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463468de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# improvements: use LSTMs or GRUs, multiple layers, Adam, LR scheduler, bidirectional RNNs\n",
    "# it's overfitting pretty good when using a GRU with bidirectional\n",
    "# the predictions still look pretty bad...no doubt due to batching and use of bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "ee5dca34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t y r a n o e p e s u s o s s s <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, seed, max_len, output_len):\n",
    "    tokens = pad([stoi[char.lower()] for char in seed], stoi['<PAD>'], max_len)\n",
    "    for i in range(max_len - len(seed)):\n",
    "        x = F.one_hot(torch.tensor(tokens)).float()\n",
    "        yhat = model(x)\n",
    "        probs = yhat.softmax(dim=-1).detach().numpy()[len(seed) + i]\n",
    "        sample = stoi['<PAD>']\n",
    "        if i > output_len:\n",
    "            break\n",
    "        while sample == stoi['<PAD>'] or sample == stoi['\\n']:\n",
    "            sample = np.random.choice(vocab_size, p=probs)\n",
    "        tokens[len(seed) + i] = sample\n",
    "    return tokens\n",
    "\n",
    "seed = 'tyran'\n",
    "tokens = predict(model, seed, max_len, 10)\n",
    "batch_to_text(tokens, itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e0274",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "- Instead of one-hot encoding tokens, it's more efficient to feed their `stoi` index directly into the model via an embedding layer, which is a linear layer that takes an lookup index instead of a vector as input, and outputs a vector of specified size. \n",
    "- Mathematically, an embedding is a learned parameter matrix $E$ applied before the first layer of a neural net: $\\sigma(WEx+b)$. \n",
    "- A given token is identified directly with its embedding vector as a representation of the token in a high-dimensional space. \n",
    "- When trained, these embeddings can learn semantic relationships between tokens, taking into account the context of the token to make predictions. \n",
    "- Embeddings can also be used for unsupervised tasks, like similarity search or clustering of tokens and documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "622a3871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), torch.Size([10, 20]))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 50\n",
    "emb_size = 20\n",
    "\n",
    "x = torch.randint(0, vocab_size, size=(10,))\n",
    "emb = nn.Embedding(vocab_size, emb_size)\n",
    "y = emb(x)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c69b2",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "- Continuous Bag of Words (CBOW): Predict target word given context words\n",
    "- Skip-Gram: Predict some context word given the target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39eaf5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rkingery/opt/anaconda3/envs/main/lib/python3.10/site-packages/torch/utils/data/datapipes/utils/common.py:24: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n",
      "/Users/rkingery/opt/anaconda3/envs/main/lib/python3.10/site-packages/torch/utils/data/datapipes/iter/selecting.py:54: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\"Lambda function is not supported for pickle, please use \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40478, 4358)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_from_iter(data_iter):\n",
    "    corpus = []\n",
    "    for text in data_iter:\n",
    "        corpus.append(text)\n",
    "    return corpus\n",
    "\n",
    "train_iter = torchtext.datasets.WikiText2(split='train')\n",
    "val_iter = torchtext.datasets.WikiText2(split='valid')\n",
    "test_iter = torchtext.datasets.WikiText2(split='test')\n",
    "\n",
    "train_text = text_from_iter(train_iter) + text_from_iter(val_iter)\n",
    "test_text = text_from_iter(test_iter)\n",
    "len(train_text), len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988ed39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_special_tokens(text):\n",
    "    # put xxup token before words in all caps (easy way to recognize info from capitalizing a word)\n",
    "    text = re.sub(r'(\\b[A-Z][A-Z0-9]*\\b)', r' xxup \\1 ', text)\n",
    "    # put xxcap token before words with capitalized first letter (easy way to recognize first word in a sentence)\n",
    "    text = re.sub(r'(\\b[A-Z][a-z0-9]+\\b)', r' xxcap \\1 ', text)\n",
    "    # insert beginning and end of sentence tokens xxbos, xxeos after a period, at beginning, and strip extra xxbos\n",
    "    text = re.sub(r'( [.]+ )', r' xxeos \\1 xxbos ', text)\n",
    "    text = ' xxbos ' + text\n",
    "    # text = text[:-7]\n",
    "    # insert beginning and end of document tokens xxbod, xxeod\n",
    "    text = ' xxbed ' + text + ' xxeod '\n",
    "    return text\n",
    "\n",
    "def normalize_text(text, remove_stopwords=False, stem_text=False, punct=None, lower=True, nums=None, \n",
    "                   special_tokens=True, strip_non_ascii=False):\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    from nltk.corpus import stopwords\n",
    "    import re, string\n",
    "\n",
    "    if text.strip() == '':\n",
    "        return ''\n",
    "    # strip new lines\n",
    "    text = re.sub(r'\\n+','',text)\n",
    "    # put spaces between punctuation (eg: 9.Blah -> 9 . Blah)\n",
    "    puncts = r'[' + re.escape(string.punctuation) + r']'\n",
    "    text = re.sub('(?<! )(?=' + puncts + ')|(?<=' + puncts + ')(?! )', r' ', text)\n",
    "    # converts common patterns into special tokens\n",
    "    if special_tokens:\n",
    "        text = sub_special_tokens(text)\n",
    "    # convert text to lowercase\n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    # strip non-ascii characters (easy way to denoise text a bit)\n",
    "    if strip_non_ascii:\n",
    "        text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    # replace all punctuation with xxpunct or strip depending on value of punct\n",
    "    if punct is not None:\n",
    "        text = re.sub(r\"[^\\w\\s]\",' xxpunct ', text) if punct == 'replace' else text\n",
    "        text = re.sub(r\"[^\\w\\s]\",'', text) if punct == 'strip' else text\n",
    "    # convert all other numbers to xxnum token (e.g. 123, 1.2.3, 1-2-3 -> xxnum)\n",
    "    if nums is not None:\n",
    "        text = re.sub(r'\\b([.-]*[0-9]+[.-]*)+\\b', ' xxnum ', text) if nums == 'replace' else text\n",
    "        text = re.sub(r'\\b([.-]*[0-9]+[.-]*)+\\b', '', text) if nums == 'strip' else text\n",
    "    # remove nltk's common set of stop words (common for classical NLP analysis)\n",
    "    if remove_stopwords:\n",
    "        stop_words = stopwords.words('english')\n",
    "        text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    # stem words using nltk snowball stemmer, e.g. converts {run, running, runs} all to \"run\"\n",
    "    if stem_text:\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_text = ''\n",
    "        for word in text.split():\n",
    "                stemmed_text = stemmed_text + stemmer.stem(word) + ' '\n",
    "        text = stemmed_text\n",
    "    # sub the occurance of 2 or more spaces with a single space\n",
    "    text = re.sub(r'[ ]{2,}',' ',text)\n",
    "    text = text.strip()\n",
    "    # fix messed up <unk> tokens\n",
    "    text = re.sub(r'unk','<unk>',text)       \n",
    "    return text\n",
    "\n",
    "def tokenize_corpus(corpus, normalizer, tokenizer, **kwargs):\n",
    "    tokens = []\n",
    "    for doc in tqdm(corpus):\n",
    "        doc = normalizer(doc, **kwargs)\n",
    "        doc = tokenizer(doc).text\n",
    "        toks = doc.split(' ') if (doc != '') else ['']\n",
    "        tokens.append(toks)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a95e4098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0cd11b20164a5e86c4d9127732c178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40478 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2764c753e5774c9fb999980b23979089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(23296, 2597)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize and tokenize text\n",
    "\n",
    "tokenizer = torchtext.data.utils.get_tokenizer(nlp) # spacy tokenizer as a function\n",
    "train_tokens = tokenize_corpus(train_text, normalize_text, tokenizer, punct='strip', nums='strip', strip_non_ascii=True, special_tokens=False)\n",
    "test_tokens = tokenize_corpus(test_text, normalize_text, tokenizer, punct='strip', nums='strip', strip_non_ascii=True, special_tokens=False)\n",
    "\n",
    "train_tokens = [token for token in train_tokens if len(token) > 1]\n",
    "test_tokens = [token for token in test_tokens if len(token) > 1]\n",
    "len(train_tokens), len(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc18d8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2429"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = torchtext.vocab.build_vocab_from_iterator(train_tokens + test_tokens, max_tokens=10000, specials=['<unk>'], min_freq=100)\n",
    "vocab.append_token('<pad>')\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "stoi = vocab.get_stoi()\n",
    "itos = vocab.get_itos()\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00e7806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1866453, 198581)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process text for word2vec CBOW\n",
    "# X = context_window, y = target\n",
    "# ex: 'the quick brown fox jumped' w/ window_size=2\n",
    "# X = the quick _ fox jumped\n",
    "# y = brown\n",
    "\n",
    "def proc_for_word2vec(tokens, window_size=4, pad_token='<pad>'):\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for doc in tokens:\n",
    "        doc = [pad_token] * window_size + doc + [pad_token] * window_size\n",
    "        for i in range(window_size, len(doc) - window_size):\n",
    "            context = doc[i - window_size: i] + doc[i + 1: i + window_size + 1]\n",
    "            target = doc[i]\n",
    "            contexts.append(context)\n",
    "            targets.append(target)\n",
    "    return contexts, targets\n",
    "\n",
    "window_size = 4\n",
    "train_contexts, train_targets = proc_for_word2vec(train_tokens, window_size=window_size)\n",
    "test_contexts, test_targets = proc_for_word2vec(test_tokens, window_size=window_size)\n",
    "len(train_contexts), len(test_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57697689",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [vocab(context) for context in train_contexts]\n",
    "X_test = [vocab(context) for context in test_contexts]\n",
    "\n",
    "y_train = vocab(train_targets)\n",
    "y_test = vocab(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de4d0e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1866453, 8]),\n",
       " torch.Size([1866453]),\n",
       " torch.Size([198581, 8]),\n",
       " torch.Size([198581]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X_train).long()\n",
    "X_test = torch.tensor(X_test).long()\n",
    "y_train = torch.tensor(y_train).long()\n",
    "y_test = torch.tensor(y_test).long()\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ce4c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(X_train, y_train)\n",
    "test_data = Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6d0a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "emb_size = 300\n",
    "\n",
    "class Word2VecCBOW(nn.Module):\n",
    "    def __init__(self, window_size, vocab_size, emb_size=300):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.fc = nn.Linear(emb_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # pass each x[0, ..., context_window] through self.emb\n",
    "        x = self.emb(x)\n",
    "        # average the context_window outputs together to get an emb_size vector\n",
    "        x = torch.mean(x, dim=1)\n",
    "        # pass vector through linear layer to get vocab_size logits\n",
    "        x = self.fc(x)\n",
    "        # return logits\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bdc57fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99ba7264e594c97b2974ac2bf9a37bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2311b7ff6e0344bebdc12eda322e7344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      3\u001b[0m opt \u001b[38;5;241m=\u001b[39m get_optimizer(model, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mshow_batches_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_data, model, opt, loss_fn, test_data, num_epochs, plot_loss, batch_size, tensorboard, print_loss, show_batches_bar, shuffle)\u001b[0m\n\u001b[1;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(yhat, y)\n\u001b[1;32m     38\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 39\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m batch_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(loss)\u001b[38;5;241m*\u001b[39m batch_size)\n\u001b[1;32m     41\u001b[0m batch_correct\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m((yhat\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mcpu()))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.10/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.10/site-packages/torch/optim/_functional.py:110\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    105\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    109\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[0;32m--> 110\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Word2VecCBOW(window_size, vocab_size, emb_size=emb_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = get_optimizer(model, optimizer='adam', lr=0.001, weight_decay=0.0001)\n",
    "model = train_model(train_data, model, opt, loss_fn, num_epochs=5, batch_size=128, test_data=test_data,\n",
    "                   show_batches_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc119f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdda128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7dbcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
