{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f698d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import timm\n",
    "import fastai.text.all as fastai\n",
    "from fastai.callback.schedule import Learner\n",
    "import transformers\n",
    "\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from tensorboardX import SummaryWriter\n",
    "# %load_ext tensorboard\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "import torchtext\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "# pip install ipyexperiments\n",
    "# from ipyexperiments import IPyExperimentsCPU, IPyExperimentsPytorch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed + 1)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e714e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e08695",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd() / 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac15a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, optimizer='sgd', lr=0.001, weight_decay=0, momentum=0, betas=(0.9, 0.999), eps=1e-8):\n",
    "    if optimizer == 'sgd':\n",
    "        opt = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=lr, \n",
    "            weight_decay=weight_decay, \n",
    "            momentum=momentum\n",
    "        )\n",
    "    if optimizer == 'adam':\n",
    "        opt = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            betas=betas,\n",
    "            eps=eps\n",
    "        )\n",
    "    if optimizer == 'radam':\n",
    "        opt = torch.optim.RAdam(\n",
    "            model.parameters(),\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            betas=betas,\n",
    "            eps=eps\n",
    "        )\n",
    "    return opt\n",
    "\n",
    "def train_classifier(train_data, model, opt, loss_fn, test_data=None, num_epochs=10, plot_loss=True, batch_size=32,\n",
    "                     tensorboard=False, print_stats=True, show_batches_bar=False, shuffle=True, scheduler=None,\n",
    "                     print_every=1, n_grad_accums=1, use_multi_gpus=False, collate_fn=None, pin_memory=False,\n",
    "                     device=device):\n",
    "    from torch.utils.data import DataLoader\n",
    "    if tensorboard:\n",
    "        writer = SummaryWriter()\n",
    "    losses = []\n",
    "    num_workers = 1 if device == 'cuda' else 0\n",
    "    pin_memory = True if (pin_memory and device == 'cuda') else False\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn, \n",
    "                              num_workers=num_workers, pin_memory=pin_memory)\n",
    "    if test_data is not None:\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, \n",
    "                                 num_workers=num_workers, pin_memory=pin_memory)\n",
    "    if use_multi_gpus:\n",
    "        orig_model = model\n",
    "        model = nn.DataParallel(model)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model = model.train()\n",
    "        total_losses = []\n",
    "        total_correct = []\n",
    "        iterator = tqdm(train_loader, leave=False) if show_batches_bar else train_loader\n",
    "        for i, (X, y) in enumerate(iterator):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            yhat = model(X)\n",
    "            loss = loss_fn(yhat, y).mean() # mean is for multi-gpu losses, avg them together\n",
    "            loss /= n_grad_accums # rescale loss for grad accumulation\n",
    "            loss.backward()\n",
    "            if i % n_grad_accums == 0: # only step when every n_grad_accums grad updates\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "            total_losses.append(float(loss))\n",
    "            total_correct.append(float((yhat.argmax(dim=1) == y).sum().cpu()))\n",
    "        train_loss = np.mean(total_losses)\n",
    "        train_acc = sum(total_correct) / len(train_data)\n",
    "        losses.append(train_loss)\n",
    "        \n",
    "        if test_data is not None:\n",
    "            model = model.eval()\n",
    "            opt.zero_grad()\n",
    "            total_losses = []\n",
    "            total_correct = []\n",
    "            iterator = tqdm(test_loader, leave=False) if show_batches_bar else test_loader\n",
    "            for X, y in iterator:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                yhat = model(X)\n",
    "                loss = loss_fn(yhat, y).mean()\n",
    "                total_losses.append(float(loss))\n",
    "                total_correct.append(float((yhat.argmax(dim=1) == y).sum().cpu()))\n",
    "            test_loss = np.mean(total_losses)\n",
    "            test_acc = sum(total_correct) / len(test_data)\n",
    "        else:\n",
    "            test_loss = -999\n",
    "            test_acc = -999\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        if tensorboard:\n",
    "            writer.add_scalar(\"Training Loss\", train_loss, epoch+1)\n",
    "            writer.add_scalar(\"Training Accuracy\", train_acc, epoch+1)\n",
    "            writer.add_scalar(\"Test Loss\", test_loss, epoch+1)\n",
    "            writer.add_scalar(\"Test Accuracy\", test_acc, epoch+1)\n",
    "        if print_stats and epoch % print_every == 0:\n",
    "            s1 = f'epoch: {epoch: <3}   ' \n",
    "            s2 = f'train loss: {round(train_loss, 5): <6}   train acc: {round(train_acc, 5): <6}   ' \n",
    "            s3 = f'test loss: {round(test_loss, 5): <6}   test acc: {round(test_acc, 5): <6}'\n",
    "            print(s1 + s2 + s3)\n",
    "    if plot_loss:\n",
    "        plt.plot(range(len(losses)), losses)\n",
    "        plt.title('Training Loss')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.show()\n",
    "    if tensorboard:\n",
    "        writer.flush()\n",
    "        writer.close()\n",
    "    model = model if not use_multi_gpus else orig_model\n",
    "    return model\n",
    "\n",
    "def train_seq2seq(train_data, model, opt, loss_fn, model_type, test_data=None, num_epochs=10, plot_loss=True, \n",
    "                  batch_size=32, tensorboard=False, print_stats=True, show_batches_bar=False, shuffle=True, \n",
    "                  scheduler=None, print_every=1, n_grad_accums=1, use_multi_gpus=False, grad_clip=1, \n",
    "                  teacher_forcing=0.5, collate_fn=None, pin_memory=False, device=device):\n",
    "    from torch.utils.data import DataLoader\n",
    "    if tensorboard:\n",
    "        writer = SummaryWriter()\n",
    "    losses = []\n",
    "    num_workers = 1 if device == 'cuda' else 0\n",
    "    pin_memory = True if (pin_memory and device == 'cuda') else False\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn, \n",
    "                              num_workers=num_workers, pin_memory=pin_memory)\n",
    "    if test_data is not None:\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, \n",
    "                                 num_workers=num_workers, pin_memory=pin_memory)\n",
    "    if use_multi_gpus:\n",
    "        orig_model = model\n",
    "        model = nn.DataParallel(model)\n",
    "       \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model = model.train()\n",
    "        total_losses = []\n",
    "        iterator = tqdm(train_loader, leave=False) if show_batches_bar else train_loader\n",
    "        # if not specified, use heavy teacher forcing early in training and decay it linearly to zero\n",
    "        teacher_forcing = (1 - epoch / num_epochs) * teacher_forcing\n",
    "        for i, (X, Y) in enumerate(iterator):\n",
    "            X = X.to(device).long()\n",
    "            Y = Y.to(device).long()\n",
    "            bs, bptt = Y.shape[0], Y.shape[1]\n",
    "            if model_type == 'seq2seq_rnn':\n",
    "                Yhat = model(X, h=None, Y=Y, teacher_forcing=teacher_forcing)\n",
    "            if model_type == 'seq2seq_transformer':\n",
    "                Yhat = model(X, Y=Y)\n",
    "            if model_type == 'lm_rnn':\n",
    "                Yhat = model(X, h=None)\n",
    "            if model_type == 'lm_transformer':\n",
    "                Yhat = model(X)\n",
    "            y = Y.reshape(bs * bptt,)\n",
    "            yhat = Yhat.reshape(bs * bptt, -1)\n",
    "            loss = loss_fn(yhat, y).mean() # mean is for multi-gpu losses, avg them together\n",
    "            loss /= n_grad_accums # rescale loss for grad accumulation\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            if i % n_grad_accums == 0: # only step when every n_grad_accums grad updates\n",
    "                opt.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                opt.zero_grad()\n",
    "            total_losses.append(float(loss))\n",
    "            if tensorboard:\n",
    "                iters = epoch * len(train_loader) + i\n",
    "                writer.add_scalar(\"Training Loss\", float(loss), iters)\n",
    "        train_loss = np.mean(total_losses)\n",
    "        losses.append(train_loss)\n",
    "        \n",
    "        if test_data is not None:\n",
    "            model = model.eval()\n",
    "            opt.zero_grad()\n",
    "            total_losses = []\n",
    "            iterator = tqdm(test_loader, leave=False) if show_batches_bar else test_loader\n",
    "            for X, Y in iterator:\n",
    "                X = X.to(device)\n",
    "                Y = Y.to(device)\n",
    "                bs, bptt = Y.shape[0], Y.shape[1]\n",
    "                if model_type == 'rnn':\n",
    "                    Yhat = model(X, h=None, Y=Y)\n",
    "                if model_type == 'seq2seq_transformer':\n",
    "                    Yhat = model(X, Y=Y)\n",
    "                if model_type == 'lm_rnn':\n",
    "                    Yhat = model(X, h=None)\n",
    "                if model_type == 'lm_transformer':\n",
    "                    Yhat = model(X)\n",
    "                y = Y.reshape(bs * bptt,)\n",
    "                yhat = Yhat.reshape(bs * bptt, -1)\n",
    "                loss = loss_fn(yhat, y).mean()\n",
    "                total_losses.append(float(loss))\n",
    "            test_loss = np.mean(total_losses)\n",
    "        else:\n",
    "            test_loss = -999\n",
    "            \n",
    "        if tensorboard:\n",
    "            writer.add_scalar(\"Test Loss\", test_loss, epoch)\n",
    "        if print_stats and (epoch % print_every == 0) or (epoch == num_epochs - 1):\n",
    "            s1 = f'epoch: {epoch: <3}   ' \n",
    "            s2 = f'train loss: {round(train_loss, 5): <6}   test loss: {round(test_loss, 5): <6}' \n",
    "            print(s1 + s2)\n",
    "    if plot_loss:\n",
    "        plt.plot(range(len(losses)), losses)\n",
    "        plt.title('Training Loss')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.show()\n",
    "    if tensorboard:\n",
    "        writer.flush()\n",
    "        writer.close()\n",
    "    model = model if not use_multi_gpus else orig_model\n",
    "    return model\n",
    "\n",
    "def predict(test_data, model, batch_size=32, collate_fn=None, device=device):\n",
    "    from torch.utils.data import DataLoader\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=False)\n",
    "    model = model.eval()\n",
    "    preds = []\n",
    "    for X, y in tqdm(test_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        yhat = model(X).detach()\n",
    "        preds.append(yhat.argmax(dim=-1).cpu())\n",
    "    preds = torch.cat(preds, dim=0).flatten()\n",
    "    return preds\n",
    "\n",
    "def predict_seq2seq(data, model, model_type, batch_size=32, collate_fn=None, device=device):\n",
    "    # returns sequence flattened predictions *and* sequence flattened targets (y, yhat)\n",
    "    # y.shape = yhat.shape = (bs * bptt,)\n",
    "    from torch.utils.data import DataLoader\n",
    "    data_loader = DataLoader(data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=False) \n",
    "    model = model.eval()\n",
    "    yhat = []\n",
    "    y = []\n",
    "    for X, Y in tqdm(data_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        bs, bptt = Y.shape\n",
    "        if model_type == 'seq2seq_rnn':\n",
    "            Yhat = model(X, h=None, Y=Y).detach()\n",
    "        if model_type == 'seq2seq_transformer':\n",
    "            Yhat = model(X, Y=Y).detach()\n",
    "        if model_type == 'lm_rnn':\n",
    "            Yhat = model(X, h=None).detach()\n",
    "        if model_type == 'lm_transformer':\n",
    "            Yhat = model(X).detach()\n",
    "        yhat.append(Yhat.reshape(bs * bptt, -1).argmax(dim=-1).cpu())\n",
    "        y.append(Y.reshape(bs * bptt, -1).cpu())\n",
    "    yhat = torch.cat(yhat, dim=0).flatten()\n",
    "    y = torch.cat(y, dim=0).flatten()\n",
    "    return yhat, y\n",
    "\n",
    "def func_over_batches(func, data, model, model_type=None, batch_size=32, collate_fn=None, device=device,\n",
    "                      flatten_seqs=False):\n",
    "    from torch.utils.data import DataLoader\n",
    "    data_loader = DataLoader(data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=False) \n",
    "    model = model.eval()\n",
    "    scores = []\n",
    "    for X, Y in tqdm(data_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        if model_type is None:\n",
    "            Yhat = model(X).detach()\n",
    "        if model_type == 'seq2seq_rnn':\n",
    "            Yhat = model(X, h=None, Y=Y).detach()\n",
    "        if model_type == 'seq2seq_transformer':\n",
    "            Yhat = model(X, Y=Y).detach()\n",
    "        if model_type == 'lm_rnn':\n",
    "            Yhat = model(X, h=None).detach()\n",
    "        if flatten_seqs:\n",
    "            bs, bptt = Y.shape\n",
    "            Yhat = Yhat.reshape(bs * bptt, -1).squeeze()\n",
    "            Y = Y.reshape(bs * bptt, -1).squeeze()\n",
    "        score = func(Yhat, Y)\n",
    "        scores.append(float(score))\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "def garbage_collect():\n",
    "    import gc\n",
    "    return gc.collect()\n",
    "\n",
    "def text_from_iter(data_iter):\n",
    "    corpus = []\n",
    "    for text in data_iter:\n",
    "        corpus.append(text)\n",
    "    return corpus\n",
    "\n",
    "def accuracy(yhat, y):\n",
    "    return (y == yhat).sum().item() / len(y)\n",
    "\n",
    "def clean_text(tokens):\n",
    "    text = []\n",
    "    prev_token = '<bos>'\n",
    "    for token in tokens:\n",
    "        if token != '<unk>':\n",
    "            if prev_token == '<up>':\n",
    "                token = token.upper()\n",
    "            if prev_token == '<cap>':\n",
    "                token = token.title()\n",
    "        if token == '@-@':\n",
    "            token = '-'\n",
    "        if token not in ['<bos>', '<eos>', '<up>', '<cap>']:\n",
    "            text.append(token)\n",
    "        prev_token = token\n",
    "    return ' '.join(text)\n",
    "\n",
    "def generate_text(seed, model, vocab, tokenizer, max_len=20, temperature=0.5, device=device, skip_tokens=['<unk>']):\n",
    "    stoi, itos = vocab.get_stoi(), vocab.get_itos()\n",
    "    model = model.eval()\n",
    "    seed_tokens = ['<bos>'] + tokenizer(seed)\n",
    "    x = torch.tensor([stoi[word] for word in seed_tokens]).long().to(device)[None, :]\n",
    "    idxs = []\n",
    "    probs = []\n",
    "    idx_prev = stoi['<unk>']\n",
    "    for _ in range(max_len):\n",
    "        yhat = model(x)\n",
    "        prob = yhat[:, -1].softmax(dim=-1)\n",
    "        if (torch.rand(1) < temperature) or (idx_prev in [stoi[token] for token in skip_tokens]):\n",
    "            idx = torch.multinomial(prob, 1, replacement=True).item()\n",
    "        else:\n",
    "            idx = prob.argmax(-1).item()\n",
    "        idxs.append(idx)\n",
    "        probs.append(prob.unsqueeze(dim=1))\n",
    "        x = torch.cat([x, torch.ones(1, 1).fill_(idx).long().to(device)], dim=1)\n",
    "        idx_prev = idx\n",
    "        if itos[idx] == '<eos>':\n",
    "            break\n",
    "    probs = torch.cat(probs, dim=1)\n",
    "    generated = [itos[idx] for idx in idxs]\n",
    "    text = seed + ' ' + clean_text(generated)\n",
    "    return text\n",
    "\n",
    "def swa(train_data, model, optimizer, num_iters=1000, swa_lr=0.0001, batch_size=32, collate_fn=None):\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    swa_model = torch.optim.swa_utils.AveragedModel(model).to(device)\n",
    "    swa_scheduler = torch.optim.swa_utils.SWALR(optimizer, swa_lr=swa_lr)\n",
    "    for i in tqdm(range(num_iters)):\n",
    "        swa_model.update_parameters(model)\n",
    "        swa_scheduler.step()\n",
    "    torch.optim.swa_utils.update_bn(train_loader, swa_model)\n",
    "    return swa_model\n",
    "\n",
    "def gpu_mem_restore(func):\n",
    "    \"reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    \"execute by decorating functions with: @gpu_mem_restore; def func(...):\"\n",
    "    import functools, traceback\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = sys.exc_info()\n",
    "            traceback.clear_frames(tb)\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper\n",
    "\n",
    "class gpu_mem_restore_ctx():\n",
    "    \"context manager to reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    \"execute by calling with gpu_mem_restore_ctx(): <stuff>\"\n",
    "    import functools, traceback\n",
    "    def __enter__(self): return self\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if not exc_val: return True\n",
    "        traceback.clear_frames(exc_tb)\n",
    "        raise exc_type(exc_val).with_traceback(exc_tb) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53f3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=F.relu, layer_norm_eps=1e-5, \n",
    "                 batch_first=True, norm_first=False, device=device, dtype=None, alpha=1, beta=1):\n",
    "        kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=batch_first, **kwargs)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward, **kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model, **kwargs)\n",
    "        self.norm_first = norm_first if not (alpha == 1 and beta == 1) else False # deepnorm reqs post-norm\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps, **kwargs)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps, **kwargs)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.alpha = alpha # NEW\n",
    "        self.beta = beta # NEW\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if 'activation' not in state:\n",
    "            state['activation'] = F.relu\n",
    "        super().__setstate__(state)\n",
    "\n",
    "    def forward(self, x, src_mask=None, src_key_padding_mask=None):\n",
    "        if self.norm_first:\n",
    "            x = self.alpha * x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask) # UPDATED\n",
    "            x = self.alpha * x + self._ff_block(self.norm2(x)) # UPDATED\n",
    "        else:\n",
    "            x = self.norm1(self.alpha * x + self._sa_block(x, src_mask, src_key_padding_mask)) # UPDATED\n",
    "            x = self.norm2(self.alpha * x + self._ff_block(x)) # UPDATED\n",
    "        return x\n",
    "\n",
    "    def _sa_block(self, x, attn_mask, key_padding_mask):\n",
    "        q, k, v = x / self.beta, x / self.beta, x # NEW\n",
    "        x = self.self_attn(q, k, v, attn_mask=attn_mask, key_padding_mask=key_padding_mask, need_weights=False)[0]\n",
    "        return self.dropout1(x)\n",
    "\n",
    "    def _ff_block(self, x):\n",
    "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        return self.dropout2(x)\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size, max_len=5000, N=10_000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len)[:, None]\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2) * (-torch.log(torch.tensor(N) / emb_size)))\n",
    "        self.encoding = torch.zeros(max_len, 1, emb_size)\n",
    "        self.encoding[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = y.shape = (batch_size, seq_len, emb_size)\n",
    "        batch_size = x.shape[0]\n",
    "        p = self.encoding[:batch_size].to(device)\n",
    "        x += p\n",
    "        y = self.dropout(x)\n",
    "        return y\n",
    "    \n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, input_size, output_size, emb_size, num_layers=256, nhead=8, dropout=0.1, dim_feedforward=256,\n",
    "                 masking=False, max_len=1024, tie_weights=False, padding_idx=None):\n",
    "        super().__init__()\n",
    "        self.masking = masking\n",
    "        self.padding_idx = padding_idx\n",
    "        self.mask = torch.triu(torch.ones(max_len, max_len)*(-torch.inf), diagonal=1).to(device)\n",
    "        self.positional = PositionalEncoding(emb_size, dropout=dropout)\n",
    "        self.in_embedding = nn.Embedding(input_size, emb_size, padding_idx=padding_idx)\n",
    "        self.out_embedding = nn.Embedding(output_size, emb_size, padding_idx=padding_idx)\n",
    "        if tie_weights:\n",
    "            self.out_embedding.weight = self.in_embedding.weight\n",
    "        self.transformer = nn.Transformer(emb_size, nhead, num_layers, num_layers, dropout=dropout, batch_first=True, \n",
    "                                          dim_feedforward=dim_feedforward)\n",
    "        self.fc = nn.Linear(emb_size, output_size)\n",
    "        \n",
    "    def forward(self, X, Y=None):\n",
    "        # X.shape = Y.shape = (batch_size, seq_len)\n",
    "        # Yhat.shape = (batch_size, seq_len, output_size)\n",
    "        batch_size, seq_len = X.shape\n",
    "        mask = self.mask[:seq_len, :seq_len] if self.masking else None\n",
    "        pad_mask_X = (X == self.padding_idx) if self.padding_idx is not None else None\n",
    "        pad_mask_Y = (Y == self.padding_idx) if self.padding_idx is not None else None\n",
    "        X = self.in_embedding(X)\n",
    "        X = self.positional(X)\n",
    "        Y = self.out_embedding(Y)\n",
    "        Y = self.positional(Y)\n",
    "        Yhat = self.transformer(X, Y, mask, mask, None, pad_mask_X, pad_mask_Y)\n",
    "        del mask\n",
    "        Yhat = self.fc(Yhat)\n",
    "        return Yhat\n",
    "    \n",
    "    def encoder(self, X):\n",
    "        batch_size, seq_len = X.shape\n",
    "        mask = self.mask[:seq_len, :seq_len] if self.masking else None\n",
    "        pad_mask = (X == self.padding_idx) if self.padding_idx is not None else None\n",
    "        X = self.in_embedding(X)\n",
    "        X = self.positional(X)\n",
    "        Xhat = self.transformer.encoder(X, mask, pad_mask)\n",
    "        del mask\n",
    "        return Xhat\n",
    "    \n",
    "    def decoder(self, Y, Xhat):\n",
    "        batch_size, seq_len = Y.shape\n",
    "        mask = self.mask[:seq_len, :seq_len] if self.masking else None\n",
    "        pad_mask = (Y == self.padding_idx) if self.padding_idx is not None else None\n",
    "        Y = self.in_embedding(Y)\n",
    "        Y = self.positional(Y)\n",
    "        Yhat = self.transformer.decoder(Y, Xhat, mask, pad_mask)\n",
    "        del mask\n",
    "        return Yhat\n",
    "    \n",
    "class EncoderLM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, num_layers=3, nhead=8, dropout=0.1, dim_feedforward=256,\n",
    "                 masking=False, max_len=1024, padding_idx=None, deepnorm=False, activation=nn.GELU(),\n",
    "                 norm_first=False):\n",
    "        super().__init__()\n",
    "        self.masking = masking\n",
    "        self.padding_idx = padding_idx\n",
    "        self.emb_size = emb_size\n",
    "        self.alpha = (2 * num_layers)**(1/4) if deepnorm else 1\n",
    "        self.beta = (8 * num_layers)**(-1/4) if deepnorm else 1\n",
    "        self.mask = torch.triu(torch.ones(max_len, max_len)*(-torch.inf), diagonal=1).to(device)\n",
    "        self.positional = PositionalEncoding(emb_size, dropout=dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=padding_idx)\n",
    "        self.transformer = nn.TransformerEncoder(ModifiedTransformerEncoderLayer(\n",
    "            emb_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True, \n",
    "            alpha=self.alpha, beta=self.beta, activation=activation, norm_first=norm_first), num_layers)\n",
    "        self.fc = nn.Linear(emb_size, vocab_size)\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X.shape = (batch_size, seq_len)\n",
    "        # Yhat.shape = (batch_size, seq_len, vocab_size)\n",
    "        batch_size, seq_len = X.shape\n",
    "        mask = self.mask[:seq_len, :seq_len] if self.masking else None\n",
    "        pad_mask = (X == self.padding_idx) if self.padding_idx is not None else None\n",
    "        X = self.embedding(X) * torch.sqrt(torch.tensor(self.emb_size))\n",
    "        X = self.positional(X)\n",
    "        X = self.transformer(X, mask, pad_mask)\n",
    "        X = self.fc(X)\n",
    "        return X\n",
    "    \n",
    "    def init_weights(self, layer):\n",
    "        if isinstance(layer, nn.modules.linear.Linear) or \\\n",
    "           isinstance(layer, nn.modules.sparse.Embedding) or \\\n",
    "           isinstance(layer, nn.modules.linear.NonDynamicallyQuantizableLinear):\n",
    "            torch.nn.init.xavier_normal_(layer.weight, gain=self.beta)\n",
    "            \n",
    "class Seq2SeqCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss(**kwargs)\n",
    "\n",
    "    def forward(self, Yhat, Y):\n",
    "        bs, bptt = Y.shape[0], Y.shape[1]\n",
    "        y = Y.reshape(bs * bptt,)\n",
    "        yhat = Yhat.reshape(bs * bptt, -1)\n",
    "        loss = self.loss_fn(yhat, y).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ab00c",
   "metadata": {},
   "source": [
    "## Language Model Training on Wikitext103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec22e50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1805110, 4358)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = torchtext.datasets.WikiText103(split='train')\n",
    "val_iter = torchtext.datasets.WikiText103(split='valid')\n",
    "test_iter = torchtext.datasets.WikiText103(split='test')\n",
    "\n",
    "train_text = text_from_iter(train_iter) + text_from_iter(val_iter)\n",
    "test_text = text_from_iter(test_iter)\n",
    "len(train_text), len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b9816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92563b99e956467e99c8cc0255d32419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1805110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd16f3479074488d9118d15595e2b272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4358 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sub_special_tokens(text):\n",
    "    # put <up> token before words in all caps (easy way to recognize info from capitalizing a word)\n",
    "    text = re.sub(r'(\\b[A-Z][A-Z0-9]*\\b)', r' <up> \\1 ', text)\n",
    "    # put <cap> token before words with capitalized first letter (easy way to recognize first word in a sentence)\n",
    "    text = re.sub(r'(\\b[A-Z][a-z0-9]+\\b)', r' <cap> \\1 ', text)\n",
    "    return text\n",
    "\n",
    "min_tokens = 5\n",
    "max_tokens = 512\n",
    "\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "# sp_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
    "# sp_model = torchtext.data.functional.load_sp_model(sp_path)\n",
    "# tokenizer = torchtext.data.functional.sentencepiece_tokenizer(sp_model)\n",
    "train_data = [tokenizer(sub_special_tokens(doc)) for doc in tqdm(train_text)]\n",
    "test_data = [tokenizer(sub_special_tokens(doc)) for doc in tqdm(test_text)]\n",
    "\n",
    "train_data = [['<bos>'] + doc[:max_tokens] + ['<eos>'] for doc in train_data if len(doc) > min_tokens]\n",
    "test_data = [['<bos>'] + doc[:max_tokens] + ['<eos>'] for doc in test_data if len(doc) > min_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa265172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 30_000\n",
    "specials = ['<unk>', '<pad>', '<bos>', '<eos>', '<up>', '<cap>']\n",
    "vocab = torchtext.vocab.build_vocab_from_iterator(train_data, max_tokens=vocab_size+1, specials=specials, \n",
    "                                                  special_first=True)\n",
    "vocab.set_default_index(vocab['<unk>']) # must do this to deal with unknown tokens or will get key errors!\n",
    "stoi = vocab.get_stoi()\n",
    "itos = vocab.get_itos()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1031003c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1140799, 2758)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6bf8884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 318]), torch.Size([10, 318]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collate_fn(batch, vocab=vocab):\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    stoi = vocab.get_stoi()\n",
    "    pad_token = stoi['<pad>']\n",
    "    X = [torch.tensor(vocab(doc)).long() for doc in batch]\n",
    "    X = pad_sequence(X, batch_first=True, padding_value=pad_token)\n",
    "    Y = torch.roll(X, shifts=-1, dims=1)\n",
    "    Y[:, -1] = pad_token\n",
    "    return X, Y\n",
    "\n",
    "batch = train_data[:10]\n",
    "X, Y = collate_fn(batch, vocab=vocab)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61fd459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "emb_size = 768\n",
    "dim_feedforward = 2048\n",
    "num_layers = 8\n",
    "nhead = 12\n",
    "padding_idx = stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0abb6a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90215724\n"
     ]
    }
   ],
   "source": [
    "model = EncoderLM(vocab_size, emb_size, num_layers=num_layers, nhead=nhead, dim_feedforward=dim_feedforward,\n",
    "                  masking=True, padding_idx=padding_idx, dropout=0.1, max_len=525, deepnorm=True).to(device)\n",
    "print(sum([p.numel() for p in model.parameters()]))\n",
    "del model\n",
    "garbage_collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "731602d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=9.120108734350652e-05)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, collate_fn=collate_fn, num_workers=1,\n",
    "                          pin_memory=True, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, collate_fn=collate_fn, num_workers=1,\n",
    "                         pin_memory=True, shuffle=False)\n",
    "dls = fastai.DataLoaders(train_loader, test_loader)\n",
    "\n",
    "model = EncoderLM(vocab_size, emb_size, num_layers=num_layers, nhead=nhead, dim_feedforward=dim_feedforward,\n",
    "                  masking=True, padding_idx=padding_idx, dropout=0.07, max_len=525, deepnorm=True).to(device)\n",
    "loss_fn = Seq2SeqCrossEntropyLoss(ignore_index=padding_idx)\n",
    "\n",
    "learn = Learner(dls, model, loss_func=loss_fn, metrics=fastai.accuracy, opt_func=fastai.Adam,\n",
    "                cbs=[fastai.GradientClip]) #, fastai.MixedPrecision])\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e8778f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 1e-4) # train loss: 3.396, test loss: 3.647\n",
    "torch.save(learn.model.state_dict(), model_path / 'lm_8_layers.pth')\n",
    "torch.save(vocab, model_path / 'vocab_8_layers.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5285735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = np.random.choice(train_data, size=200_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1bf9aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = DataLoader(train_sample, batch_size=batch_size, collate_fn=collate_fn, num_workers=1,\n",
    "                          pin_memory=True, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, collate_fn=collate_fn, num_workers=1,\n",
    "                         pin_memory=True, shuffle=False)\n",
    "dls = fastai.DataLoaders(train_loader, test_loader)\n",
    "\n",
    "model = EncoderLM(vocab_size, emb_size, num_layers=num_layers, nhead=8, dim_feedforward=dim_feedforward,\n",
    "                  masking=True, padding_idx=padding_idx, dropout=0.1, max_len=525, deepnorm=True).to(device)\n",
    "model.load_state_dict(torch.load(model_path / 'lm_8_layers.pth', map_location=torch.device(device)))\n",
    "vocab = torch.load(model_path / 'vocab_8_layers.pth')\n",
    "\n",
    "loss_fn = Seq2SeqCrossEntropyLoss(ignore_index=padding_idx)\n",
    "\n",
    "learn = Learner(dls, model, loss_func=loss_fn, metrics=fastai.accuracy, opt_func=fastai.Adam,\n",
    "                cbs=[fastai.GradientClip])\n",
    "\n",
    "# learn.lr_find(start_lr=1e-8, end_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95926c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.495250</td>\n",
       "      <td>3.399788</td>\n",
       "      <td>0.155488</td>\n",
       "      <td>1:16:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-5, wd=1e-10)\n",
    "torch.save(learn.model.state_dict(), model_path / 'lm_8_layers.pth')\n",
    "torch.save(vocab, model_path / 'vocab_8_layers.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24a5d294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.466055</td>\n",
       "      <td>3.392943</td>\n",
       "      <td>0.155903</td>\n",
       "      <td>2:31:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-6, wd=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e18ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learn.model.state_dict(), model_path / 'lm_8_layers.pth')\n",
    "torch.save(vocab, model_path / 'vocab_8_layers.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e730fe3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4587edd715546bf915b7be6cc0bc56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([614864]), torch.Size([614864]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, yhat = predict_seq2seq(test_data, learn.model, model_type='lm_transformer', batch_size=8, collate_fn=collate_fn)\n",
    "y.shape, yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad2f667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17513629030159514"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy(y, yhat)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b2006e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4d3de2720c44feb0e1106af5411c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/173 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.3924907935148028"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=padding_idx)\n",
    "loss = func_over_batches(loss_fn, test_data, learn.model, batch_size=16, collate_fn=collate_fn, flatten_seqs=True)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d2147cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_tokens = ['<unk>', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e5619b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a story about his father ' s life . He travels to Jacksonville , Florida , where he visits Sixteenth Thomas Street , where he encounters <unk> ( <unk> Street ) , a military component . He is promptly arrested by <unk> , and unsuccessful , although he is adept at firing his shotgun . He claims he extensively on the security arrangements by accurate space and <unk> , and is unsuccessful . He is also mr . <unk> Street and takes his name from the <unk>\n"
     ]
    }
   ],
   "source": [
    "seed = 'This is a story about'\n",
    "print(generate_text(seed, model, vocab, tokenizer, max_len=100, temperature=0.7, skip_tokens=skip_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "326e6380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2b193655d64c9ea4f59969a0bcfd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=0)\n",
    "swa_model = swa(train_data, model, opt, swa_lr=3e-6, num_iters=10_000, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73e36d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1875b52c4d7445bcbf46ca209e6b2126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/230 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4355b022b641d091edb8d26b8ddfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/230 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3.395088297387828, 0.16128495937881948)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, yhat = predict_seq2seq(test_data, swa_model, model_type='lm_transformer', batch_size=12, collate_fn=collate_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=padding_idx)\n",
    "loss = func_over_batches(loss_fn, test_data, swa_model, batch_size=12, collate_fn=collate_fn, flatten_seqs=True)\n",
    "acc = accuracy(y, yhat)\n",
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d88a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a story about civil war that follows the Great War of the United States . According to <unk> , the Great War Memorial is sometimes referred to as the Fourth Civil War memorial at a <unk> with Britain ' s War Memorial Memorial Chapel .\n"
     ]
    }
   ],
   "source": [
    "seed = 'This is a story about'\n",
    "print(generate_text(seed, swa_model, vocab, tokenizer, max_len=100, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af666b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f8753ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_loader\n",
    "del test_loader\n",
    "del dls\n",
    "del loss_fn\n",
    "del model\n",
    "learn.destroy()\n",
    "del learn\n",
    "torch.cuda.empty_cache()\n",
    "garbage_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee445a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e19440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d60cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
